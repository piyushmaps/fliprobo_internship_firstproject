{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the data which is required by client\n",
    "designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "location=driver.find_element_by_id(\"qsb-location-sugg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation.send_keys(\"Data analyst\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now based on the required detailes we require selenium to search the page\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button[1]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of required field\n",
    "job_title=[]\n",
    "location=[]\n",
    "job_ex=[]\n",
    "comp_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements_by_xpath(\"//div[@class='info fleft']/a[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_tags:\n",
    "    if i.text is None:\n",
    "        job_title.append(\"-\")\n",
    "    else:\n",
    "        job_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loc_tags:\n",
    "    if i.text is None:\n",
    "        location.append(\"-\")\n",
    "    else:\n",
    "        location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tags[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in exp_tags:\n",
    "    if i.text is None:\n",
    "        job_ex.append(\"-\")\n",
    "    else:\n",
    "        job_ex.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in name_tags:\n",
    "    if i.text is None:\n",
    "        comp_name.append(\"-\")\n",
    "    else:\n",
    "        comp_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\n",
    "    \"comp_name\":comp_name,\n",
    "    \"job_eperience\":job_ex,\n",
    "    \"job_title\":job_title,\n",
    "    \"job_location\":location\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data. Note- 1. All of the above steps have to be done in code. No step is to be done manually. WEB SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")\n",
    "\n",
    "url=\"https://www.naukri.com/\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "#entering the data which is required by client\n",
    "designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "\n",
    "designation.send_keys(\"Data analyst\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "#Now based on the required detailes we require selenium to search the page\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button[1]\")\n",
    "search_button.click()\n",
    "\n",
    "#list of required field\n",
    "job_title=[]\n",
    "location=[]\n",
    "full_job_description=[]\n",
    "comp_name=[]\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//div[@class='info fleft']/a[1]\")\n",
    "\n",
    "for i in title_tags:\n",
    "    if i.text is None:\n",
    "        job_title.append(\"-\")\n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "job_title\n",
    "\n",
    "len(job_title)\n",
    "\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "loc_tags[0]\n",
    "\n",
    "\n",
    "\n",
    "for i in loc_tags:\n",
    "    if i.text is None:\n",
    "        location.append(\"-\")\n",
    "    else:\n",
    "        location.append(i.text)\n",
    "\n",
    "location[0]\n",
    "\n",
    "len(location)\n",
    "\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "exp_tags[0].text\n",
    "\n",
    "for i in exp_tags:\n",
    "    if i.text is None:\n",
    "        job_ex.append(\"-\")\n",
    "    else:\n",
    "        job_ex.append(i.text)\n",
    "\n",
    "job_ex[0]\n",
    "\n",
    "len(job_ex)\n",
    "\n",
    "name_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "name_tags[0].text\n",
    "\n",
    "for i in name_tags:\n",
    "    if i.text is None:\n",
    "        comp_name.append(\"-\")\n",
    "    else:\n",
    "        comp_name.append(i.text)\n",
    "        \n",
    "        \n",
    "# scraping the full job-description, for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"---\")\n",
    "\n",
    "comp_name\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    \"comp_name\":comp_name,\n",
    "    \"job_description\":job_description,\n",
    "    \"job_title\":job_title,\n",
    "    \"job_location\":location\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the location check box\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='Delhi/NCR']\")\n",
    "\n",
    "# clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the salary check box\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "\n",
    "# clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Only Fresher / Data Scientist / Data Analyst / Business Analytics- MNC',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Business Analytics- MNC']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi NCR, Ghaziabad, Gurgaon', 'Faridabad, Delhi NCR, Greater Noida']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-0 Yrs', '0-0 Yrs']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    " #scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Delhi NCR, Ghaziabad, Gurgaon</td>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Faridabad, Delhi NCR, Greater Noida</td>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>WellMed Medical Management</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>(3 Reviews)</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Data Scientist/Analyst - Machine Learning/Deep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                            company_name  \\\n",
       "0             0-0 Yrs               GABA Consultancy services   \n",
       "1             0-0 Yrs               GABA Consultancy services   \n",
       "2             4-8 Yrs              WellMed Medical Management   \n",
       "3             1-5 Yrs  AlgoScale Technologies Private Limited   \n",
       "4             3-6 Yrs                             (3 Reviews)   \n",
       "\n",
       "                          job_location  \\\n",
       "0        Delhi NCR, Ghaziabad, Gurgaon   \n",
       "1  Faridabad, Delhi NCR, Greater Noida   \n",
       "2                                Noida   \n",
       "3                                Noida   \n",
       "4                                Delhi   \n",
       "\n",
       "                                           job_title  \n",
       "0  Only Fresher / Data Scientist / Data Analyst /...  \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...  \n",
       "2                           Associate Data Scientist  \n",
       "3                                     Data Scientist  \n",
       "4  Data Scientist/Analyst - Machine Learning/Deep...  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "WEB SCRAPING ASSIGNMENT-2\n",
    ".\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.glassdoor.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your login credentials in the chrome window opened by webdriver. Do this step manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.keyword']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.location']\"))).send_keys(\"Noida\")\n",
    "\n",
    "\n",
    "#search_field_designation=driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "#search_field_designation.send_keys(\"Data Scientist\")\n",
    "#search_field_location=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "#search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "\n",
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xtLytics', 'xtLytics']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where company name is present\n",
    "companies=driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']/span\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '3']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where ratings of the company  is present\n",
    "ratings=driver.find_elements_by_xpath(\"//span[@class='compactStars ']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "company_ratings[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '2']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where  No. of days ago when job was posted is present\n",
    "days=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text[0])\n",
    "days_ago[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_ratings</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xtLytics</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xtLytics</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RiseIn Technologies Pvt Ltd</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unyscape Infocom Pvt. Ltd</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  company_name company_ratings days_ago\n",
       "0                     xtLytics               3        2\n",
       "1                     xtLytics               3        2\n",
       "2  RiseIn Technologies Pvt Ltd             3.1        3\n",
       "3    Unyscape Infocom Pvt. Ltd             3.9        1\n",
       "4                     Ericsson               4        2"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"company_ratings\":company_ratings[0:10],\"days_ago\":days_ago[0:10]\n",
    "                })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company\n",
    "name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='KeywordSearch']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='LocationSearch']\"))).send_keys(\"Noida\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_salaries=[]\n",
    "max_salaries=[]\n",
    "average_salaries=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹706K', '₹572K']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where min salary   is present\n",
    "min_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")\n",
    "for i in min_salary:\n",
    "    if i.text is None :\n",
    "        min_salaries.append(\"--\") \n",
    "    else:\n",
    "        \n",
    "        min_salaries.append(i.text)\n",
    "min_salaries[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹11,513K', '₹1,300K']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where max salary   is present\n",
    "max_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "for i in max_salary:\n",
    "    if i.text is None :\n",
    "        max_salaries.append(\"--\") \n",
    "    else:\n",
    "        max_salaries.append(i.text)\n",
    "max_salaries[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹11,513K', '₹1,300K']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where average salary   is present\n",
    "average_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "for i in average_salary:\n",
    "    if i.text is None :\n",
    "        average_salaries.append(\"--\") \n",
    "    else:\n",
    "        average_salaries.append(i.text)\n",
    "average_salaries[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhivery', 'Accenture']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where company_name   is present\n",
    "company=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "for i in company:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\")      \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"\":company_ratings[0:10],\"days_ago\":days_ago[0:10]\n",
    "                })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount \n",
    "To scrape \n",
    "the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User 14\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name('LM6RPg')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sunglasses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('vh79eN')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 3 page\n",
    "    brands=driver.find_elements_by_class_name('_2B_pmu')#scraping brands name by class name='_2B_pmu'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_class_name('_2mylT6')#scraping description by class name = '_2mylT6'\n",
    "    for i in desc:\n",
    "        description.append(i.get_attribute('title'))#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_1vC4OE']\")# scraping the price from the xpath\n",
    "    for i in prices[:40]:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='VGWI6T']\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_2Xp0TH']\")#scraping the list of buttons from the page\n",
    "    driver.get(nxt_button[page].get_attribute('href'))#getting the link from the list for next page\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Brand                                        Description  \\\n",
      "0             Levi's                     Others Aviator Sunglasses (58)   \n",
      "1             Fossil  Mirrored, UV Protection Rectangular Sunglasses...   \n",
      "2           Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
      "3             Collet  Gradient, Mirrored, UV Protection Aviator Sung...   \n",
      "4          Elligator                UV Protection Round Sunglasses (54)   \n",
      "..               ...                                                ...   \n",
      "95              INSH  UV Protection, Night Vision, Riding Glasses Re...   \n",
      "96          Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
      "97  shah collections         UV Protection Round Sunglasses (Free Size)   \n",
      "98    kingsunglasses  Mirrored, UV Protection Wayfarer, Wayfarer, Wa...   \n",
      "99            Fossil                 Others Rectangular Sunglasses (54)   \n",
      "\n",
      "     Price Discount  \n",
      "0   ₹5,180  30% off  \n",
      "1   ₹2,420  45% off  \n",
      "2     ₹674  25% off  \n",
      "3     ₹199  86% off  \n",
      "4     ₹312  87% off  \n",
      "..     ...      ...  \n",
      "95    ₹327  86% off  \n",
      "96    ₹719  20% off  \n",
      "97    ₹331  80% off  \n",
      "98    ₹269  82% off  \n",
      "99  ₹2,200  50% off  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8:Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising driver\n",
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name('LM6RPg')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "button=driver.find_element_by_class_name('vh79eN')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 3 page\n",
    "    brands=driver.find_elements_by_class_name('_2B_pmu')#scraping brands name by class name='_2B_pmu'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_class_name('_2mylT6')#scraping description by class name = '_2mylT6'\n",
    "    for i in desc:\n",
    "        description.append(i.get_attribute('title'))#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_1vC4OE']\")# scraping the price from the xpath\n",
    "    for i in prices[:40]:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='VGWI6T']\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_2Xp0TH']\")#scraping the list of buttons from the page\n",
    "    driver.get(nxt_button[page].get_attribute('href'))#getting the link from the list for next page\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Brand                                        Description   Price  \\\n",
      "0      WROGN                                   Sneakers For Men  ₹1,424   \n",
      "1      WROGN                                   Sneakers For Men  ₹1,349   \n",
      "2     Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹461   \n",
      "3     Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...    ₹236   \n",
      "4     Chevit  Chevit Latest Fashion Combo Pack of 2 Pairs Ca...    ₹525   \n",
      "..       ...                                                ...     ...   \n",
      "95    Rontex                                   Sneakers For Men    ₹426   \n",
      "96  Claptrap  Mesh Walking Casual Sneakers Shoes for Men And...    ₹449   \n",
      "97  PERY-PAO                White Casual Shoes Sneakers For Men    ₹425   \n",
      "98   Shoefly  Combo Men Pack of 2 Loafers Shoes Sneakers For...    ₹331   \n",
      "99  Red Tape                                   Sneakers For Men  ₹1,023   \n",
      "\n",
      "   Discount  \n",
      "0   50% off  \n",
      "1   50% off  \n",
      "2   76% off  \n",
      "3   52% off  \n",
      "4   64% off  \n",
      "..      ...  \n",
      "95  57% off  \n",
      "96  10% off  \n",
      "97  57% off  \n",
      "98  66% off  \n",
      "99  75% off  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10:  Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising driver\n",
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")\n",
    "driver.get(' https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(\"laptops\")                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
    "search_button.click()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating Ratings\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception\n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")#locating the ratingd link\n",
    "        rate.click()                                                      #click the rating link found\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each list\n",
    "print(len(Title))\n",
    "print(len(price))\n",
    "print(len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title   Price       Ratings\n",
      "0  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...  81,990  4.1 out of 5\n",
      "1  Dell Inspiron 5370 13.3-inch FHD Laptop (Core ...  68,490  4.1 out of 5\n",
      "2  (Renewed) Dell Inspiron 3567 Laptop Core i3-7t...  37,900     NO rating\n",
      "3  (Renewed) Dell Latitude E5570 15-inch Laptop (...  61,999     NO rating\n",
      "4  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...  82,789  3.8 out of 5\n",
      "5  (Renewed) Dell Latitude E7240 12.5-inch Laptop...  39,999  3.6 out of 5\n",
      "6  Lenovo Legion 5i 10th Gen Intel i7 15.6\" FHD G...  81,489  4.1 out of 5\n",
      "7  (Renewed) HP EliteBook 1030 G2 X 360 Notebook ...  49,990  2.2 out of 5\n",
      "8  Dell 2019 Dell Inspiron 14 5482 14 Inch FHD 2-...  57,490    4 out of 5\n",
      "9  (Renewed) HP EliteBook X360 1030 G2 Laptop (Co...  49,990  2.6 out of 5\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.\"https://www.myntra.com/shoes\". Set price filter \"Rs 6649 to Rs 13099\" and color filter to \"Black\" and then scrap 100 shoes data. The data should include \"Brand\" of shoes, shoe short-description and price. Please not: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")\n",
    "driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&rf=Price%3A6649.0_13099.0_6649.0%20TO%2013099.0%2C6337.0_10225.0_6337.0%20TO%2010225.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Brand                         Short-description  \\\n",
      "0             Reebok            Harmony 3.5 Road Running Shoes   \n",
      "1               Puma            Trailfox Overland MTS Grid Run   \n",
      "2             ADIDAS                 Men Questar Flow Sneakers   \n",
      "3               Geox               Women Solid Leather Loafers   \n",
      "4               Nike                    Men Zoom Running Shoes   \n",
      "5             ADIDAS               Men FluidFlow Running Shoes   \n",
      "6               Nike              Men AIR MAX Basketball Shoes   \n",
      "7     ROSSO BRUNELLO  Men Solid Italian Leather Formal Loafers   \n",
      "8               ALDO              Women Leather Open Toe Flats   \n",
      "9             Reebok                 Men Nano X Training Shoes   \n",
      "10              Nike                    Men Zoom Running Shoes   \n",
      "11              Geox                 Men Leather Formal Derbys   \n",
      "12              Geox                    Women Leather Slip-Ons   \n",
      "13            ADIDAS               Men Galaxar Run Sustainable   \n",
      "14      Kenneth Cole           Men Solid Leather Formal Derbys   \n",
      "15              Puma                         Men Running Shoes   \n",
      "16              Geox                       Men Leather Loafers   \n",
      "17              ALDO          Men Solid Leather Formal Oxfords   \n",
      "18            ADIDAS               Men Dame 6 Basketball Shoes   \n",
      "19              Geox               Men Leather Formal Slip-Ons   \n",
      "20              Geox                 Men Leather Driving Shoes   \n",
      "21              Nike                  Women ZOOM Running Shoes   \n",
      "22            ADIDAS            Men Edge Gameday Running Shoes   \n",
      "23          Skechers             Men Go Run Ride Running Shoes   \n",
      "24      Hush Puppies         Men Solid Leather Formal Slip-Ons   \n",
      "25              Geox                 Men Leather Driving Shoes   \n",
      "26            DIESEL                     Men DANNY LC Sneakers   \n",
      "27            ADIDAS                 Men Energy Falcon Running   \n",
      "28              Puma             Men SPEED 500 2 Running Shoes   \n",
      "29              Geox               Men Leather Formal Slip-Ons   \n",
      "30              ALDO                         Men Solid Loafers   \n",
      "31            Clarks                Men Leather Formal Brogues   \n",
      "32              Geox                Men Solid Leather Sneakers   \n",
      "33              Geox                  Women Leather Boat Shoes   \n",
      "34  ADIDAS Originals                    Men SEELEY Skate Shoes   \n",
      "35              Geox                 Men Leather Formal Derbys   \n",
      "36              ALDO              Men Textured Leather Loafers   \n",
      "37      UNDER ARMOUR             Charged Aurora Training Shoes   \n",
      "38         Cole Haan               Men Wingtip Oxford Sneakers   \n",
      "39              Xtep                         Men Running Shoes   \n",
      "40              Geox                  Women Sequinned Sneakers   \n",
      "41              Geox                Men Woven Slip-On Sneakers   \n",
      "42      UNDER ARMOUR            Charged Bandit 5 Running Shoes   \n",
      "43            DIESEL                      Men Mid-Top Sneakers   \n",
      "44         Cole Haan                          Leather Sneakers   \n",
      "45              Geox                Men Leather Formal Loafers   \n",
      "46         Cole Haan       Men Traveller Leather Penny Loafers   \n",
      "47              Xtep                         Men Running Shoes   \n",
      "48            Reebok                   Men HIIT Training Shoes   \n",
      "49              ALDO                       Men Leather Loafers   \n",
      "\n",
      "                              Price  \n",
      "0                         Rs. 11999  \n",
      "1    Rs. 6999Rs. 9999(Rs. 3000 OFF)  \n",
      "2                          Rs. 6999  \n",
      "3                          Rs. 7999  \n",
      "4                          Rs. 7995  \n",
      "5                          Rs. 7999  \n",
      "6                          Rs. 7995  \n",
      "7        Rs. 7699Rs. 10999(30% OFF)  \n",
      "8                          Rs. 6999  \n",
      "9                          Rs. 9999  \n",
      "10                         Rs. 7995  \n",
      "11                        Rs. 12990  \n",
      "12                         Rs. 8990  \n",
      "13   Rs. 6399Rs. 7999(Rs. 1600 OFF)  \n",
      "14        Rs. 6643Rs. 9490(30% OFF)  \n",
      "15                         Rs. 6999  \n",
      "16                        Rs. 10990  \n",
      "17  Rs. 6999Rs. 13999(Rs. 7000 OFF)  \n",
      "18  Rs. 8199Rs. 10999(Rs. 2800 OFF)  \n",
      "19                         Rs. 9490  \n",
      "20                         Rs. 7999  \n",
      "21                         Rs. 7995  \n",
      "22   Rs. 6399Rs. 7999(Rs. 1600 OFF)  \n",
      "23   Rs. 7899Rs. 8999(Rs. 1100 OFF)  \n",
      "24        Rs. 7649Rs. 8999(15% OFF)  \n",
      "25                         Rs. 9499  \n",
      "26       Rs. 9093Rs. 13990(35% OFF)  \n",
      "27                         Rs. 6999  \n",
      "28   Rs. 6999Rs. 9999(Rs. 3000 OFF)  \n",
      "29                        Rs. 12990  \n",
      "30                        Rs. 11999  \n",
      "31                         Rs. 7999  \n",
      "32                        Rs. 10999  \n",
      "33                         Rs. 8990  \n",
      "34                         Rs. 6999  \n",
      "35                        Rs. 12990  \n",
      "36                        Rs. 12999  \n",
      "37                         Rs. 6999  \n",
      "38                        Rs. 12999  \n",
      "39       Rs. 9899Rs. 10999(10% OFF)  \n",
      "40       Rs. 6599Rs. 10999(40% OFF)  \n",
      "41                        Rs. 10990  \n",
      "42                         Rs. 7999  \n",
      "43     Rs. 7800Rs. 13000( 40 % OFF)  \n",
      "44                        Rs. 10999  \n",
      "45                         Rs. 8499  \n",
      "46       Rs. 8999Rs. 19999(55% OFF)  \n",
      "47        Rs. 6569Rs. 7299(10% OFF)  \n",
      "48   Rs. 7199Rs. 8999(Rs. 1800 OFF)  \n",
      "49                        Rs. 12999  \n"
     ]
    }
   ],
   "source": [
    "start_page=0\n",
    "end_page=0\n",
    "for page in range(start_page,end_page+1): \n",
    "    nxt_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "    \n",
    "    #creating empty lists\n",
    "    shoe_names=[]\n",
    "    s_desc=[]\n",
    "    short_desc=[]\n",
    "    price=[]\n",
    "    \n",
    "    #for scrapping shoe brand names\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    #for scrapping shoe short-description\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    #As, the s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    #for scrapping shoe prices\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for i in desc:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    #for scrapping the datas from next pages.\n",
    "    if nxt_button.text=='next':\n",
    "            nxt_button.click()\n",
    "            time.sleep(5)\n",
    "            \n",
    "    #creating a dataframe to store above scraped details\n",
    "    df=pd.DataFrame({'Brand': shoe_names,\n",
    "                    'Short-description': short_desc,\n",
    "                    'Price': price})\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 flipkart iphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer starts from here\n",
    "\n",
    "driver=webdriver.Firefox(executable_path=r\"C:\\Users\\Admin\\AppData\\Local\\Temp\\geckodriver.exe\")\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Creating empty list\n",
    "urls=[]\n",
    "short_desc=[]\n",
    "desc=[]\n",
    "stars=[]\n",
    "\n",
    "#Taking 10 pages into consideration using for loop\n",
    "for i in range(10):\n",
    "    url=driver.find_element_by_xpath(\"//a[@class='_2Xp0TH']\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='col _390CkK _1gY8H-']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\"):\n",
    "        short_desc.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='qwjRop']/div/div\"):\n",
    "        desc.append(l.text)\n",
    "#printing the length of lists\n",
    "print(len(stars))\n",
    "print(len(short_desc))\n",
    "print(len(desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of Stars      Short Description  \\\n",
      "0                5      Terrific purchase   \n",
      "1                5              Wonderful   \n",
      "2                5          Great product   \n",
      "3                5  Mind-blowing purchase   \n",
      "4                5      Terrific purchase   \n",
      "..             ...                    ...   \n",
      "95               5      Worth every penny   \n",
      "96               5      Worth every penny   \n",
      "97               5       Perfect product!   \n",
      "98               4           Nice product   \n",
      "99               5              Wonderful   \n",
      "\n",
      "                                          Description  \n",
      "0   Upgraded from iphone 6 to 11 best phone for ip...  \n",
      "1   This is my first ever I phone. Before this I w...  \n",
      "2   Well you all know the specifications . One of ...  \n",
      "3   This will help you more. See if you are planni...  \n",
      "4   The built quality is not very premium.\\nThe ba...  \n",
      "..                                                ...  \n",
      "95  Best budget Iphone till date ❤️ go for it guys...  \n",
      "96  It’s been almost a month since I have been usi...  \n",
      "97  Iphone is just awesome.. battery backup is ver...  \n",
      "98  Awesome Phone. Slightly high price but worth. ...  \n",
      "99  *Review after 10 months of usage*\\nDoesn't see...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Combining all the lists into a single dataframe\n",
    "df=pd.DataFrame({'Stars': stars,\n",
    "                'sr Description': short_desc,\n",
    "               'Descr': desc})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
